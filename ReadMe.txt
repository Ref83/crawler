WebCrawler - Библиотека загрузки веб ресурсов в локальную директорию.

Используется парсер HTML - HtmlAgilityPack (для возможности легкой замены он спрятан за интерфейсом).

WebCrawler обрабатывает следующие типы html тегов
	- a
	- link
	- script
	- img

Загрузка всех ресурсов происходит параллельно с максимально разрешенным количеством потоков загрузки (по умолчанию 10).
Есть возможность ограничения загрузки из доменов не равных стартовому домену.
Так же возможно ограничить глубину прохода. На последнем уровне обхода ссылки в html странице на локальные не подменяются.
При сохранении на локальный диск все вышеперечисленные теги подменяются на ссылками на локальные ресурсы.
Нет возможность отменить начавшуюся загрузку.
Библиотека позволяет загружать разные ресурсы параллельно - произведя нескольких запусков метода Crawler.Crawl. 
Библиотека обрабатывает циклические ссылки и не загружает уже загруженные страницы повторно.
После загрузки метод возвращает список загруженных ссылок указанием где можно найти загруженный файл в локальном каталоге. 
Если при загрузке страницы будет ошибка - вместо указания локального пути будет сообщение ошибки.
В данной библиотеке не проробатывался вопрос получения данных через защищенный конал или через proxy.
